---
---
@InProceedings{2019_CVPR_Shweta,
  author    = {Shweta Bharathwaj, Mukundhan Srinivasan and Mitesh M. Khapra},
  title     = {Efficient Video Classification Using Fewer Frames},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2019},
}

@InProceedings{ISMRM19CARING-NVIDIA,
  author    = {Vidur Mahajan, and Aravind Upadhyaya, and Vasantha Kumar Venugopal, and Abhishek S Venkataram, and Mukundhan Srinivasan, and Murali Murugavel, and Harsh Mahajan},
  title     = {Virtual Imaging Using Generative Adversarial Networks for Image Translation (VIGANIT): Prediction of Diffusion-Weighted Images from T2-Weighted Brain MR Images},
  booktitle = {ISMRM Annual Meeting},
  year      = {2019},
  abstract  = {100 whole brain MRI scans of patients with no abnormality and 30 with acute infarcts, comprising of 25 T2-weighted and Diffusion-Weighted (b=1000) images each, were fed into a Deep Learning model with a 75-25 training-validation split. The T2W image was assigned as the input to predict DW images. Binary Cross entropy of 0.15 for normal and 0.11 for infarct cases was obtained and the predicted images were able to successfully delineate acute and chronic infarcts in all test cases.},
  url       = {https://submissions.mirasmart.com/ISMRM2019/ViewSubmissionPublic.aspx?sei=RStYpbRcd}
}

@InProceedings{ISBI19-Deb-Mukund-IITKGP-NVDA,
  author    = {Debarghya China, and Francis Tom, and Sumanth Nandamuri, and Aupendu Kar, and Pabitra Mitra, and Mukundhan Srinivasan, and Debdoot Sheet},
  title     = {UltraCompression: Framework for High Density Compression of Ultrasound Volumes using Physics Modeling Deep Neural Networks},
  booktitle = {The IEEE International Symposium on Biomedical Imaging (ISBI) },
  publisher = {{IEEE} Press},
  year      = {2019},
  abstract  = {Ultrasound image compression by preserving speckle- based key information is a quite challenging task. In this paper, we introduce an ultrasound image compression frame- work with the ability to retain realism of speckle appearance despite achieving very high-density compression factors. The compressor employs a tissue segmentation method transmit- ting segments along with transducer frequency, number of samples and image size as essential information required for decompressing to generate the image. The decompressor is based on a convolutional network trained to generate patho- realistic ultrasound images which convey essential informa- tion pertinent to tissue pathology visible in the images. We demonstrate generalizability of the building blocks using two variants to build the compressor, employing (i) a graph cut and random forest learning-based method for segmentation and (ii) convolutional neural network based semantic seg- mentation. We have evaluated the quality of decompressed images using distortion losses as well as perception loss and compared it with other off the shelf available solutions. The proposed framework helps to compress the image with a compression ratio of 750 : 1 and the statistical distribution of the decompressed image follows same as the original image which helps to segment the image based on statistical me- chanical understanding of ultrasound-tissue interaction, and we have achieved dice score of 0.89Â±0.11 which outperforms than the existing methods.},
  url       = {https://biomedicalimaging.org/2019/}
}

@InProceedings{AAAI_2019_IITM_NVIDIA_MSFTIDC,
  author    = {Ananya Sai B, and Mithun Das Gupta, and Mitesh M. Khapra, and Mukundhan Srinivasan},
  title     = {Re-evaluating ADEM: A Deeper Look at Scoring Dialogue Responses},
  booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), Hawaii USA},
  publisher = {{AAAI} Press},
  abstract  = {Automatically evaluating the quality of dialogue re- sponses for unstructured domains is a challenging problem. ADEM (Lowe et al. (2017)) formulated the automatic evalu- ation of dialogue systems as a learning problem and showed that such a model was able to predict responses which corre- late significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report ex- periments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the short- comings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system.},
  year      = {2019},
  url       = {https://aaai.org/Conferences/AAAI-19/aaai-19-program-overview/}
}

@InProceedings{Sam_2018_CVPR,
  author = {Babu Sam, Deepak and Sajjan, Neeraj N. and Venkatesh Babu, R. and Srinivasan, Mukundhan},
  title = {Divide and Grow: Capturing Huge Diversity in Crowd Images With Incrementally Growing CNN},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  abstract = {Automated counting of people in crowd images is a challenging task. The major difficulty stems from the large diversity in the way people appear in crowds. In fact, features available for crowd discrimination largely depend on the crowd density to the extent that people are only seen as blobs in a highly dense scene. We tackle this problem with a growing CNN which can progressively increase its capacity to account for the wide variability seen in crowd scenes. Our model starts from a base CNN density regressor, which is trained in equivalence on all types of crowd images. In order to adapt with the huge diversity, we create two child regressors which are exact copies of the base CNN. A differential training procedure divides the dataset into two clusters and fine-tunes the child networks on their respective specialties. Consequently, without any hand-crafted criteria for forming specialties, the child regressors become experts on certain types of crowds. The child networks are again split recursively, creating two experts at every division. This hierarchical training leads to a CNN tree, where the child regressors are more fine experts than any of their parents. The leaf nodes are taken as the final experts and a classifier network is then trained to predict the correct specialty for a given test image patch. The proposed model achieves higher count accuracy on major crowd datasets. Further, we analyse the characteristics of specialties mined automatically by our method.},
  month = {June},
  year = {2018},
  url = {http://openaccess.thecvf.com/content_cvpr_2018/html/2726.html}
}

@INPROCEEDINGS{7050658, 
  author={Srinivasan, Mukundhan}, 
  booktitle={2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)}, 
  title={Using Bayesian statistics and Gabor Wavelets for recognition of human faces: A Markov Random Field Framework}, 
  year={2015}, 
  volume={}, 
  number={}, 
  pages={1-6}, 
  keywords={Bayes methods;face recognition;image classification;image matching;Markov processes;maximum likelihood estimation;minimisation;random processes;vectors;wavelet transforms;human face recognition;Markov random fields;Bayesian models;feature vectors;close proximity system;2D Gabor wavelet transform;constraint configurations;MRF posterior probability;MRF configuration;matching constraints;test image;maximum-a-posteriori solution;MAP solution;Mahalanobis distance metrics;expected similarity score;ESOP minimization algorithm;Bayesian statistics;Face recognition;Vectors;Databases;Computational modeling;Measurement;Image recognition;Feature extraction;Markov Random Fields;Gabor Wavelets;Face Recognition}, 
  doi={10.1109/ICAPR.2015.7050658}, 
  ISSN={}, 
  month={Jan},
}

@INPROCEEDINGS{7064600, 
  author={Srinivasan, Mukundhan and H. P. Venkata}, 
  booktitle={2014 13th International Conference on Control Automation Robotics Vision (ICARCV)}, 
  title={Towards better veracity for breast cancer detection using Gabor analysis and statistical learning}, 
  year={2014}, 
  volume={}, 
  number={}, 
  pages={1864-1869}, 
  abstract={Breast Cancer is by far the most prevalent cancer diagnosed in women worldwide. Early diagnosis and detection is now possible through modern technology like mammography. In this paper, we present a method to augment the detection process by efficiently recognizing the carcinogenic tissue or cells. To address this issue, we propose an algorithm using Discrete Gabor Wavelet Transforms based on Hidden Markov Model for classification. We test our proposed method on the Mini Mammographie Image Analysis Society (MIAS) database. The proposed method yields about 90% recognition accuracy. This increase in accuracy is due to the statistical classification of benign and malignant cells.}, 
  keywords={biological organs;biological tissues;cancer;cellular biophysics;discrete wavelet transforms;hidden Markov models;image classification;image recognition;mammography;medical image processing;breast cancer detection;gabor analysis;statistical learning;prevalent cancer diagnosis;carcinogenic tissue;carcinogenic cells;discrete gabor wavelet transforms;hidden Markov model;mini mammographic image analysis society database;MIAS database;image recognition;statistical classification;benign cells;malignant cells;image classification;Breast cancer;Hidden Markov models;Vectors;Feature extraction;Accuracy}, 
  doi={10.1109/ICARCV.2014.7064600}, 
  ISSN={}, 
  month={Dec},
}