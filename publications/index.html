<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Mukundhan Srinivasan | publications</title>
  <meta name="description" content="Mukundhan Srinivasan's Website.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/"> 
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Mukundhan</strong> Srinivasan
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Some recent papers describing research motivations & directions</h5>
  </header>

  <article class="post-content publications clearfix">
    <p><a href="https://scholar.google.com/citations?user=MahZ6toAAAAJ"> Google Scholar |</a> <a href="https://dblp.uni-trier.de/pers/hy/s/Srinivasan:Mukundhan"> DBLP </a></p>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="Bhardwaj2019EfficientVC">
  
    <span class="title">Efficient Video Classification Using Fewer Frames</span>
    <span class="author">
      
        
          
            
              Bhardwaj, Shweta,
            
          
        
      
        
          
            <em>Srinivasan, Mukundhan</em>,
          
        
      
        
          and
          
            
              Khapra, Mitesh M.
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="ISMRM19CARING-NVIDIA">
  
    <span class="title">Virtual Imaging Using Generative Adversarial Networks for Image Translation (VIGANIT): Prediction of Diffusion-Weighted Images from T2-Weighted Brain MR Images</span>
    <span class="author">
      
        
          
            
              Mahajan, Vidur,
            
          
        
      
        
          
            
              Upadhyaya, Aravind,
            
          
        
      
        
          
            
              Venugopal, Vasantha Kumar,
            
          
        
      
        
          
            
              Venkataram, Abhishek S,
            
          
        
      
        
          
            <em>Srinivasan, Mukundhan</em>,
          
        
      
        
          
            
              Murugavel, Murali,
            
          
        
      
        
          and
          
            
              Mahajan, Harsh
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ISMRM Annual Meeting</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>100 whole brain MRI scans of patients with no abnormality and 30 with acute infarcts, comprising of 25 T2-weighted and Diffusion-Weighted (b=1000) images each, were fed into a Deep Learning model with a 75-25 training-validation split. The T2W image was assigned as the input to predict DW images. Binary Cross entropy of 0.15 for normal and 0.11 for infarct cases was obtained and the predicted images were able to successfully delineate acute and chronic infarcts in all test cases.</p>
  </span>
  
</div>
</li>
<li>

<div id="ISBI19-Deb-Mukund-IITKGP-NVDA">
  
    <span class="title">UltraCompression: Framework for High Density Compression of Ultrasound Volumes using Physics Modeling Deep Neural Networks</span>
    <span class="author">
      
        
          
            
              China, Debarghya,
            
          
        
      
        
          
            
              Tom, Francis,
            
          
        
      
        
          
            
              Nandamuri, Sumanth,
            
          
        
      
        
          
            
              Kar, Aupendu,
            
          
        
      
        
          
            
              Mitra, Pabitra,
            
          
        
      
        
          
            <em>Srinivasan, Mukundhan</em>,
          
        
      
        
          and
          
            
              Sheet, Debdoot
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The IEEE International Symposium on Biomedical Imaging (ISBI) </em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Ultrasound image compression by preserving speckle- based key information is a quite challenging task. In this paper, we introduce an ultrasound image compression frame- work with the ability to retain realism of speckle appearance despite achieving very high-density compression factors. The compressor employs a tissue segmentation method transmit- ting segments along with transducer frequency, number of samples and image size as essential information required for decompressing to generate the image. The decompressor is based on a convolutional network trained to generate patho- realistic ultrasound images which convey essential informa- tion pertinent to tissue pathology visible in the images. We demonstrate generalizability of the building blocks using two variants to build the compressor, employing (i) a graph cut and random forest learning-based method for segmentation and (ii) convolutional neural network based semantic seg- mentation. We have evaluated the quality of decompressed images using distortion losses as well as perception loss and compared it with other off the shelf available solutions. The proposed framework helps to compress the image with a compression ratio of 750 : 1 and the statistical distribution of the decompressed image follows same as the original image which helps to segment the image based on statistical me- chanical understanding of ultrasound-tissue interaction, and we have achieved dice score of 0.89Â±0.11 which outperforms than the existing methods.</p>
  </span>
  
</div>
</li>
<li>

<div id="AAAI_2019_IITM_NVIDIA_MSFTIDC">
  
    <span class="title">Re-evaluating ADEM: A Deeper Look at Scoring Dialogue Responses</span>
    <span class="author">
      
        
          
            
              B, Ananya Sai,
            
          
        
      
        
          
            
              Gupta, Mithun Das,
            
          
        
      
        
          
            
              Khapra, Mitesh M.,
            
          
        
      
        
          and
          
            <em>Srinivasan, Mukundhan</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), Hawaii USA</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Automatically evaluating the quality of dialogue re- sponses for unstructured domains is a challenging problem. ADEM (Lowe et al. (2017)) formulated the automatic evalu- ation of dialogue systems as a learning problem and showed that such a model was able to predict responses which corre- late significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report ex- periments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the short- comings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="Sam_2018_CVPR">
  
    <span class="title">Divide and Grow: Capturing Huge Diversity in Crowd Images With Incrementally Growing CNN</span>
    <span class="author">
      
        
          
            
              Babu Sam, Deepak,
            
          
        
      
        
          
            
              Sajjan, Neeraj N.,
            
          
        
      
        
          
            
              <a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank">Venkatesh Babu, R.</a>,
            
          
        
      
        
          and
          
            <em>Srinivasan, Mukundhan</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Automated counting of people in crowd images is a challenging task. The major difficulty stems from the large diversity in the way people appear in crowds. In fact, features available for crowd discrimination largely depend on the crowd density to the extent that people are only seen as blobs in a highly dense scene. We tackle this problem with a growing CNN which can progressively increase its capacity to account for the wide variability seen in crowd scenes. Our model starts from a base CNN density regressor, which is trained in equivalence on all types of crowd images. In order to adapt with the huge diversity, we create two child regressors which are exact copies of the base CNN. A differential training procedure divides the dataset into two clusters and fine-tunes the child networks on their respective specialties. Consequently, without any hand-crafted criteria for forming specialties, the child regressors become experts on certain types of crowds. The child networks are again split recursively, creating two experts at every division. This hierarchical training leads to a CNN tree, where the child regressors are more fine experts than any of their parents. The leaf nodes are taken as the final experts and a classifier network is then trained to predict the correct specialty for a given test image patch. The proposed model achieves higher count accuracy on major crowd datasets. Further, we analyse the characteristics of specialties mined automatically by our method.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2015</h3>
<ol class="bibliography"><li>

<div id="7050658">
  
    <span class="title">Using Bayesian statistics and Gabor Wavelets for recognition of human faces: A Markov Random Field Framework</span>
    <span class="author">
      
        
          and
          
            <em>Srinivasan, Mukundhan</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li></ol>

<h3 class="year">2014</h3>
<ol class="bibliography"><li>

<div id="7064600">
  
    <span class="title">Towards better veracity for breast cancer detection using Gabor analysis and statistical learning</span>
    <span class="author">
      
        
          
            <em>Srinivasan, Mukundhan</em>,
          
        
      
        
          and
          
            
              Venkata, H. P.
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2014 13th International Conference on Control Automation Robotics Vision (ICARCV)</em>
    
    
      2014
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Breast Cancer is by far the most prevalent cancer diagnosed in women worldwide. Early diagnosis and detection is now possible through modern technology like mammography. In this paper, we present a method to augment the detection process by efficiently recognizing the carcinogenic tissue or cells. To address this issue, we propose an algorithm using Discrete Gabor Wavelet Transforms based on Hidden Markov Model for classification. We test our proposed method on the Mini Mammographie Image Analysis Society (MIAS) database. The proposed method yields about 90% recognition accuracy. This increase in accuracy is due to the statistical classification of benign and malignant cells.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Mukundhan Srinivasan.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-58926075-2', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
